{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather event data from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "      <th>Human voice - Shouting</th>\n",
       "      <th>Human voice - Singing</th>\n",
       "      <th>Music non-amplified</th>\n",
       "      <th>Nature elements - Wind</th>\n",
       "      <th>Transport road - Passenger car</th>\n",
       "      <th>Transport road - Siren</th>\n",
       "      <th>Unsupported</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.877161</td>\n",
       "      <td>4.700699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50.877161</td>\n",
       "      <td>4.700699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.877161</td>\n",
       "      <td>4.700699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.877161</td>\n",
       "      <td>4.700699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 01: Naamsestraat 35  Maxim</td>\n",
       "      <td>2022-03-11</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50.877161</td>\n",
       "      <td>4.700699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     description        date  Human voice - Shouting  \\\n",
       "0  MP 01: Naamsestraat 35  Maxim  2022-03-07                      10   \n",
       "1  MP 01: Naamsestraat 35  Maxim  2022-03-08                      39   \n",
       "2  MP 01: Naamsestraat 35  Maxim  2022-03-09                      28   \n",
       "3  MP 01: Naamsestraat 35  Maxim  2022-03-10                      39   \n",
       "4  MP 01: Naamsestraat 35  Maxim  2022-03-11                      70   \n",
       "\n",
       "   Human voice - Singing  Music non-amplified  Nature elements - Wind  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    1                       0   \n",
       "2                      0                    0                       0   \n",
       "3                      0                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   Transport road - Passenger car  Transport road - Siren  Unsupported  \\\n",
       "0                               4                       1            0   \n",
       "1                              20                       3            0   \n",
       "2                              42                       0            0   \n",
       "3                              27                       0            0   \n",
       "4                              44                       3            0   \n",
       "\n",
       "    latitude  longitude  \n",
       "0  50.877161   4.700699  \n",
       "1  50.877161   4.700699  \n",
       "2  50.877161   4.700699  \n",
       "3  50.877161   4.700699  \n",
       "4  50.877161   4.700699  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get merged event data\n",
    "import pandas as pd\n",
    "df_daily = pd.read_csv(\"df_final.csv\", index_col = 0)\n",
    "df_daily.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "def add_end(ts):\n",
    "  upper = pd.DataFrame(ts.iloc[0:1,:].replace([0,1], np.nan))   \n",
    "  upper['begin_date'] = pd.to_datetime('2023-01-01 00:00:00')\n",
    "  return pd.concat([ts, upper])\n",
    "\n",
    "def missing_or_noevent(ts, cutoff = 2, cutoff_Vrijthof = 7):\n",
    "  '''\n",
    "  This function fills some of the nans in the noise event variables with zeroes, based on the specified cutoff values. \n",
    "  The argument 'cutoff_Vrijthof' is used to specify the maximum length of a time period with missing values (in days!)\n",
    "  before it is considered truly missing for MP08bis, 'cutoff' does the same for all other MPs.\n",
    "  It returns two DataFrames: the adapted input DataFrame, and a DataFrame with all the missing time periods. \n",
    "  The latter is not filtered by the specified cutoffs. \n",
    "  'Unsupported' category is assumed to consist of unclassifiable events and is thus treated as an event, not missing.\n",
    "  '''\n",
    "\n",
    "  # Get time series sampling frequency\n",
    "  ts['timestamp'] = pd.to_datetime(ts['timestamp'])\n",
    "  ts = ts.sort_values(['location_csv','timestamp']).reset_index(drop=True)\n",
    "  freq = pd.to_timedelta(ts.loc[1, 'timestamp'] - ts.loc[0, 'timestamp'])\n",
    "\n",
    "  # Construct a df with the missing time periods\n",
    "  missing_time = pd.DataFrame()\n",
    "  df = ts.dropna(subset = 'human_noise')\n",
    "  missing_time[['location_csv', 'begin_date']] = df[['location_csv', 'timestamp']]\n",
    "  missing_time = missing_time.groupby('location_csv').apply(add_end).reset_index(drop=True)\n",
    "  missing_time = missing_time.sort_values([\"location_csv\",\"begin_date\"]).reset_index(drop=True)\n",
    "  missing_time['end_date'] = missing_time['begin_date'].shift(-1)\n",
    "  missing_time['begin_date'] = missing_time['begin_date'] + freq\n",
    "  missing_time['timedelta'] = missing_time.groupby(\"location_csv\")[\"begin_date\"].diff().shift(-1)\n",
    "  missing_time = missing_time.dropna()\n",
    "  missing_time = missing_time[missing_time['timedelta'] > freq]\n",
    "  missing_time['timedelta'] = missing_time['timedelta'] - freq\n",
    "\n",
    "  # Filter by cutoff values\n",
    "  true_na_vh = missing_time.loc[(missing_time['timedelta'] > timedelta(days = cutoff_Vrijthof)) & (missing_time['location_csv'] == '280324_mp08bis---vrijthof.csv')]\n",
    "  true_na_other = missing_time.loc[(missing_time['timedelta'] > timedelta(days = cutoff)) & (missing_time['location_csv'] != '280324_mp08bis---vrijthof.csv')]\n",
    "\n",
    "\n",
    "  col_to_fill = ts.columns[ts.columns.str.contains('noise')].values.tolist()\n",
    "\n",
    "  ts_vh = ts.loc[ts['location_csv'] == '280324_mp08bis---vrijthof.csv' ].copy()\n",
    "  ts_other = ts.loc[ts['location_csv'] != '280324_mp08bis---vrijthof.csv'].copy()\n",
    "\n",
    "  \n",
    "  # Add column true_na yes/no (less intervals to check for true nans than false nans)\n",
    "  # If timestamp not in true_na, replace any nans with 0s\n",
    "\n",
    "    #Vrijthof\n",
    "  ts_vh['true_na'] = ts_vh['timestamp'].apply(lambda t: any((true_na_vh[\"begin_date\"] <= t) & (true_na_vh[\"end_date\"] > t)))\n",
    "  ts_vh.loc[ts_vh['true_na'] == 0, col_to_fill] = ts_vh.loc[ts_vh['true_na'] == 0, col_to_fill].fillna(0)\n",
    "\n",
    "    #other MPs\n",
    "  other = ts_other['location_csv'].drop_duplicates().tolist()\n",
    "  for MP in other:\n",
    "    ts_other.loc[ts_other['location_csv'] == MP,'true_na'] = ts_other.loc[ts_other['location_csv'] == MP, 'timestamp'] \\\n",
    "                          .apply(lambda t: any((true_na_other['location_csv'] == MP) &(true_na_other[\"begin_date\"] <= t) & (true_na_other[\"end_date\"] > t)))\n",
    "  ts_other.loc[ts_other['true_na'] == 0, col_to_fill] = ts_other.loc[ts_other['true_na'] == 0, col_to_fill].fillna(0)\n",
    "\n",
    "  df = pd.concat([ts_vh, ts_other]).drop('true_na', axis = 1)  \n",
    "\n",
    "  return df, missing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\uygar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\uygar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\uygar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Clean up\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df, missing \u001b[39m=\u001b[39m missing_or_noevent(df_hourly)\n\u001b[0;32m      3\u001b[0m df\u001b[39m.\u001b[39mhead()\n\u001b[0;32m      4\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mbs.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m, in \u001b[0;36mmissing_or_noevent\u001b[1;34m(ts, cutoff, cutoff_Vrijthof)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mThis function fills some of the nans in the noise event variables with zeroes, based on the specified cutoff values. \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mThe argument 'cutoff_Vrijthof' is used to specify the maximum length of a time period with missing values (in days!)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m'Unsupported' category is assumed to consist of unclassifiable events and is thus treated as an event, not missing.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# Get time series sampling frequency\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m ts[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(ts[\u001b[39m'\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     21\u001b[0m ts \u001b[39m=\u001b[39m ts\u001b[39m.\u001b[39msort_values([\u001b[39m'\u001b[39m\u001b[39mlocation_csv\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m freq \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_timedelta(ts\u001b[39m.\u001b[39mloc[\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m ts\u001b[39m.\u001b[39mloc[\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\uygar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\uygar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "#Clean up\n",
    "df, missing = missing_or_noevent(df_hourly)\n",
    "df.head()\n",
    "df.to_csv('bs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model to classify police activity\n",
    "First starts with obtaining the trends data, then the cleaned data is used, merged with trends data. Trends is perhaps not the best way to approach this but access to police complaints data hourly was not possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>leuven politie</th>\n",
       "      <th>isPartial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  leuven politie isPartial\n",
       "0 2022-01-01             NaN       NaN\n",
       "1 2022-01-02            26.0     False\n",
       "2 2022-01-03             NaN       NaN\n",
       "3 2022-01-04             NaN       NaN\n",
       "4 2022-01-05             NaN       NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_trends(keyword):\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    pytrends.build_payload([keyword], cat=0, timeframe='2022-01-01 2022-12-31', geo='BE', gprop='')\n",
    "    trends = pytrends.interest_over_time()\n",
    "    return trends\n",
    "\n",
    "  # get google trends data\n",
    "trends_df = get_trends('leuven politie')\n",
    "#To see if there is a relation between human noise, and police search\n",
    "#Potentially we could use different features and different keyword for search\n",
    "\n",
    "# Create a new dataframe with a continuous date range to create NaN values \n",
    "all_dates_df = pd.DataFrame(index=pd.date_range(start='2022-01-01', end='2022-12-31'))\n",
    "\n",
    "# Merge the new dataframe with the original trends_df\n",
    "trends_df = all_dates_df.merge(trends_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "#index is date in this data\n",
    "trends_df = trends_df.reset_index()\n",
    "\n",
    "if 'index' in trends_df.columns:\n",
    "    # Strip leading/trailing whitespaces and rename the column\n",
    "    trends_df.rename(columns={'index': 'timestamp'.strip()}, inplace=True)\n",
    "else:\n",
    "    print(\"The column 'index' does not exist in the DataFrame.\")\n",
    "    \n",
    "trends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uygar\\AppData\\Local\\Temp\\ipykernel_5304\\457530992.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_daily = df.set_index('timestamp').resample('D').sum().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>human_noise</th>\n",
       "      <th>noise_event_human_voice_-_shouting</th>\n",
       "      <th>noise_event_human_voice_-_singing</th>\n",
       "      <th>noise_event_music_non-amplified</th>\n",
       "      <th>noise_event_nature_elements_-_wind</th>\n",
       "      <th>noise_event_transport_road_-_passenger_car</th>\n",
       "      <th>noise_event_transport_road_-_siren</th>\n",
       "      <th>noise_event_unsupported</th>\n",
       "      <th>#object_id</th>\n",
       "      <th>...</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>LC_RAD60</th>\n",
       "      <th>LC_TEMP_QCL0</th>\n",
       "      <th>LC_TEMP_QCL1</th>\n",
       "      <th>LC_TEMP_QCL2</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "      <th>leuven politie</th>\n",
       "      <th>isPartial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2043528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.443333</td>\n",
       "      <td>27.443333</td>\n",
       "      <td>27.163333</td>\n",
       "      <td>26.718334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6130584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039833</td>\n",
       "      <td>507.166667</td>\n",
       "      <td>10.840000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>97.465000</td>\n",
       "      <td>97.465000</td>\n",
       "      <td>96.625000</td>\n",
       "      <td>97.593354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6130584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>20.698333</td>\n",
       "      <td>128.333333</td>\n",
       "      <td>117.963333</td>\n",
       "      <td>117.963333</td>\n",
       "      <td>117.123333</td>\n",
       "      <td>117.262638</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6130584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>-49.166667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>137.500000</td>\n",
       "      <td>14.731667</td>\n",
       "      <td>14.683333</td>\n",
       "      <td>13.823000</td>\n",
       "      <td>13.493534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6130584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>165.833333</td>\n",
       "      <td>57.116667</td>\n",
       "      <td>57.116667</td>\n",
       "      <td>56.276667</td>\n",
       "      <td>56.902138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  human_noise  noise_event_human_voice_-_shouting  \\\n",
       "0 2022-01-07          2.0                                 2.0   \n",
       "1 2022-01-08          2.0                                 2.0   \n",
       "2 2022-01-09          2.0                                 2.0   \n",
       "3 2022-01-10          4.0                                 4.0   \n",
       "4 2022-01-11          3.0                                 3.0   \n",
       "\n",
       "   noise_event_human_voice_-_singing  noise_event_music_non-amplified  \\\n",
       "0                                0.0                              0.0   \n",
       "1                                0.0                              0.0   \n",
       "2                                0.0                              0.0   \n",
       "3                                0.0                              0.0   \n",
       "4                                0.0                              0.0   \n",
       "\n",
       "   noise_event_nature_elements_-_wind  \\\n",
       "0                                 0.0   \n",
       "1                                 0.0   \n",
       "2                                 0.0   \n",
       "3                                 0.0   \n",
       "4                                 0.0   \n",
       "\n",
       "   noise_event_transport_road_-_passenger_car  \\\n",
       "0                                         4.0   \n",
       "1                                         3.0   \n",
       "2                                         3.0   \n",
       "3                                         5.0   \n",
       "4                                         6.0   \n",
       "\n",
       "   noise_event_transport_road_-_siren  noise_event_unsupported  #object_id  \\\n",
       "0                                 0.0                      0.0     2043528   \n",
       "1                                 0.0                      0.0     6130584   \n",
       "2                                 0.0                      0.0     6130584   \n",
       "3                                 0.0                      0.0     6130584   \n",
       "4                                 0.0                      0.0     6130584   \n",
       "\n",
       "   ...  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED    LC_RAD60  LC_TEMP_QCL0  \\\n",
       "0  ...      0.029500   32.333333      0.058333    1.000000     27.443333   \n",
       "1  ...      0.039833  507.166667     10.840000   95.000000     97.465000   \n",
       "2  ...      0.028667  617.000000     20.698333  128.333333    117.963333   \n",
       "3  ...      0.014000  -49.166667      0.023333  137.500000     14.731667   \n",
       "4  ...      0.000000    6.000000      0.001667  165.833333     57.116667   \n",
       "\n",
       "   LC_TEMP_QCL1  LC_TEMP_QCL2  LC_TEMP_QCL3  leuven politie  isPartial  \n",
       "0     27.443333     27.163333     26.718334             NaN        NaN  \n",
       "1     97.465000     96.625000     97.593354             NaN        NaN  \n",
       "2    117.963333    117.123333    117.262638            48.0      False  \n",
       "3     14.683333     13.823000     13.493534             NaN        NaN  \n",
       "4     57.116667     56.276667     56.902138             NaN        NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resample to daily frequency, summing up the noise events\n",
    "#in order to make use of it with google trends data\n",
    "df_daily = df.set_index('timestamp').resample('D').sum().reset_index()\n",
    "\n",
    "# merge dataframes on timestamp\n",
    "merged_df = pd.merge(df_daily, trends_df, on='timestamp')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add weekend and weekday\n",
    "merged_df['day_of_week'] = merged_df['timestamp'].dt.dayofweek\n",
    "merged_df['hour_of_day'] = merged_df['timestamp'].dt.hour\n",
    "merged_df['is_weekend'] = merged_df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "import holidays\n",
    "\n",
    "be_holidays = holidays.Belgium()\n",
    "\n",
    "#add holiday data\n",
    "merged_df['is_holiday'] = merged_df['timestamp'].apply(lambda x: 1 if x in be_holidays else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444444444444444\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.83      0.62      0.71         8\n",
      "        high       0.95      0.98      0.97        64\n",
      "\n",
      "    accuracy                           0.94        72\n",
      "   macro avg       0.89      0.80      0.84        72\n",
      "weighted avg       0.94      0.94      0.94        72\n",
      "\n",
      "ROC AUC: 0.8046875\n",
      "Model saved as classifier_trends_daily.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from google.colab import files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "# create a new feature that is the sum of the noise events\n",
    "merged_df['human_noise'] = merged_df[['noise_event_human_voice_-_shouting', 'noise_event_human_voice_-_singing', 'noise_event_music_non-amplified']].sum(axis=1)\n",
    "\n",
    "# select features and target\n",
    "features = merged_df[['human_noise', 'day_of_week', 'is_weekend', 'is_holiday']]\n",
    "target = merged_df['leuven politie']\n",
    "\n",
    "# discretize the target variable into two categories: low, high\n",
    "discretizer = KBinsDiscretizer(n_bins=2, encode='ordinal', strategy='quantile')\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "target = imputer.fit_transform(target.values.reshape(-1, 1))\n",
    "#target is now numpy\n",
    "target = discretizer.fit_transform(target.reshape(-1, 1))\n",
    "# split data into training and testing sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
    "\n",
    "#pipeline with imputer\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=1000))\n",
    "])\n",
    "\n",
    "pipeline.fit(features_train, target_train.ravel())\n",
    "predictions = pipeline.predict(features_test)\n",
    "\n",
    "accuracy = accuracy_score(target_test, predictions)\n",
    "report = classification_report(target_test, predictions, target_names=['low','high'])\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report: \\n{report}')\n",
    "\n",
    "roc_auc = roc_auc_score(target_test, predictions)\n",
    "print(f'ROC AUC: {roc_auc}') #how good it is at classifying\n",
    "\n",
    "# Save the trained model as a pickle string.\n",
    "saved_model = pickle.dumps(pipeline)\n",
    "\n",
    "# Save the model to disk\n",
    "filename = 'classifier_trends_daily.pkl'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))\n",
    "\n",
    "print(\"Model saved as \" + filename)\n",
    "#files.download('classifier_trends_hour.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
