{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_csv</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>human_noise</th>\n",
       "      <th>noise_event_human_voice_-_shouting</th>\n",
       "      <th>noise_event_human_voice_-_singing</th>\n",
       "      <th>noise_event_music_non-amplified</th>\n",
       "      <th>noise_event_nature_elements_-_wind</th>\n",
       "      <th>noise_event_transport_road_-_passenger_car</th>\n",
       "      <th>noise_event_transport_road_-_siren</th>\n",
       "      <th>noise_event_unsupported</th>\n",
       "      <th>...</th>\n",
       "      <th>LC_RAD</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>LC_RAD60</th>\n",
       "      <th>LC_TEMP_QCL0</th>\n",
       "      <th>LC_TEMP_QCL1</th>\n",
       "      <th>LC_TEMP_QCL2</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255439_mp-01-naamsestraat-35-maxim.csv</td>\n",
       "      <td>2022-03-07 16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-161.5</td>\n",
       "      <td>2.215</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.381667</td>\n",
       "      <td>6.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255441_mp-03-naamsestraat-62-taste.csv</td>\n",
       "      <td>2022-03-07 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-161.5</td>\n",
       "      <td>2.215</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.381667</td>\n",
       "      <td>6.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255442_mp-05-calvariekapel-ku-leuven.csv</td>\n",
       "      <td>2022-03-07 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-161.5</td>\n",
       "      <td>2.215</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.381667</td>\n",
       "      <td>6.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255443_mp-06-parkstraat-2-la-filosovia.csv</td>\n",
       "      <td>2022-03-07 16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-161.5</td>\n",
       "      <td>2.215</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.381667</td>\n",
       "      <td>6.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255444_mp-07-naamsestraat-81.csv</td>\n",
       "      <td>2022-03-07 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-161.5</td>\n",
       "      <td>2.215</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.671667</td>\n",
       "      <td>6.381667</td>\n",
       "      <td>6.2079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 location_csv            timestamp  \\\n",
       "0      255439_mp-01-naamsestraat-35-maxim.csv  2022-03-07 16:00:00   \n",
       "1      255441_mp-03-naamsestraat-62-taste.csv  2022-03-07 16:00:00   \n",
       "2    255442_mp-05-calvariekapel-ku-leuven.csv  2022-03-07 16:00:00   \n",
       "3  255443_mp-06-parkstraat-2-la-filosovia.csv  2022-03-07 16:00:00   \n",
       "4            255444_mp-07-naamsestraat-81.csv  2022-03-07 16:00:00   \n",
       "\n",
       "   human_noise  noise_event_human_voice_-_shouting  \\\n",
       "0          0.0                                 0.0   \n",
       "1          NaN                                 NaN   \n",
       "2          NaN                                 NaN   \n",
       "3          0.0                                 0.0   \n",
       "4          NaN                                 NaN   \n",
       "\n",
       "   noise_event_human_voice_-_singing  noise_event_music_non-amplified  \\\n",
       "0                                0.0                              0.0   \n",
       "1                                NaN                              NaN   \n",
       "2                                NaN                              NaN   \n",
       "3                                0.0                              0.0   \n",
       "4                                NaN                              NaN   \n",
       "\n",
       "   noise_event_nature_elements_-_wind  \\\n",
       "0                                 0.0   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "3                                 0.0   \n",
       "4                                 NaN   \n",
       "\n",
       "   noise_event_transport_road_-_passenger_car  \\\n",
       "0                                         1.0   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         1.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   noise_event_transport_road_-_siren  noise_event_unsupported  ...  \\\n",
       "0                                 0.0                      0.0  ...   \n",
       "1                                 NaN                      NaN  ...   \n",
       "2                                 NaN                      NaN  ...   \n",
       "3                                 0.0                      0.0  ...   \n",
       "4                                 NaN                      NaN  ...   \n",
       "\n",
       "      LC_RAD LC_RAININ  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED   LC_RAD60  \\\n",
       "0  13.833333       0.0           0.0      -161.5         2.215  20.666667   \n",
       "1  13.833333       0.0           0.0      -161.5         2.215  20.666667   \n",
       "2  13.833333       0.0           0.0      -161.5         2.215  20.666667   \n",
       "3  13.833333       0.0           0.0      -161.5         2.215  20.666667   \n",
       "4  13.833333       0.0           0.0      -161.5         2.215  20.666667   \n",
       "\n",
       "   LC_TEMP_QCL0  LC_TEMP_QCL1  LC_TEMP_QCL2  LC_TEMP_QCL3  \n",
       "0      6.671667      6.671667      6.381667        6.2079  \n",
       "1      6.671667      6.671667      6.381667        6.2079  \n",
       "2      6.671667      6.671667      6.381667        6.2079  \n",
       "3      6.671667      6.671667      6.381667        6.2079  \n",
       "4      6.671667      6.671667      6.381667        6.2079  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load hourly resampled & merged df\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve('https://docs.google.com/uc?export=download&id=1--eG9u-siOXAwVvB_P_t4gxkzYcwILMa', 'merge_export41_meteoLC102_hourly.csv')\n",
    "df_hourly = pd.read_csv('merge_export41_meteoLC102_hourly.csv', index_col = 0)\n",
    "df_hourly.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguishing between true missing values and no-event 'observations'\n",
    "The time series seems to contain many missing values for noise event variables. Not all of these are true missing values, since not registering an event may simply mean there is no event. In an effort to distinguish between true missing values and no-event 'observations', we first determine the missing time periods. Considering only the gaps > 1 day, we note the following:\n",
    "\n",
    "for most locations, gaps are nearly always >= 6 days, the few exceptions have a length of 1-2 days. These exceptions may still (largely) consist of true no-event 'observations'\n",
    "\n",
    "-> (arbitrary) cutoff at 2 days?\n",
    "\n",
    "MP08bis - Vrijthof is the anomaly with 55 missing periods (vs max 5 for other locations), half of which are < 3 days, 75% of which are < 6 days. This is likely the result of its location vs that of the other locations (courtyard of the Town Hall vs along the Naamsestraat).\n",
    "\n",
    "-> (very arbitrary) cutoff at 7 days?\n",
    "\n",
    "On another note: Interestingly, most of the (supported) events registered at Vrijthof are classified as human singing. This may be linked to the nearby presence of Het Radiohuis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "def add_end(ts):\n",
    "  upper = pd.DataFrame(ts.iloc[0:1,:].replace([0,1], np.nan))   \n",
    "  upper['begin_date'] = pd.to_datetime('2023-01-01 00:00:00')\n",
    "  return pd.concat([ts, upper])\n",
    "\n",
    "def missing_or_noevent(ts, cutoff = 2, cutoff_Vrijthof = 7):\n",
    "  '''\n",
    "  This function fills some of the nans in the noise event variables with zeroes, based on the specified cutoff values. \n",
    "  The argument 'cutoff_Vrijthof' is used to specify the maximum length of a time period with missing values (in days!)\n",
    "  before it is considered truly missing for MP08bis, 'cutoff' does the same for all other MPs.\n",
    "  It returns two DataFrames: the adapted input DataFrame, and a DataFrame with all the missing time periods. \n",
    "  The latter is not filtered by the specified cutoffs. \n",
    "  'Unsupported' category is assumed to consist of unclassifiable events and is thus treated as an event, not missing.\n",
    "  '''\n",
    "\n",
    "  # Get time series sampling frequency\n",
    "  ts['timestamp'] = pd.to_datetime(ts['timestamp'])\n",
    "  ts = ts.sort_values(['location_csv','timestamp']).reset_index(drop=True)\n",
    "  freq = pd.to_timedelta(ts.loc[1, 'timestamp'] - ts.loc[0, 'timestamp'])\n",
    "\n",
    "  # Construct a df with the missing time periods\n",
    "  missing_time = pd.DataFrame()\n",
    "  df = ts.dropna(subset = 'human_noise')\n",
    "  missing_time[['location_csv', 'begin_date']] = df[['location_csv', 'timestamp']]\n",
    "  missing_time = missing_time.groupby('location_csv').apply(add_end).reset_index(drop=True)\n",
    "  missing_time = missing_time.sort_values([\"location_csv\",\"begin_date\"]).reset_index(drop=True)\n",
    "  missing_time['end_date'] = missing_time['begin_date'].shift(-1)\n",
    "  missing_time['begin_date'] = missing_time['begin_date'] + freq\n",
    "  missing_time['timedelta'] = missing_time.groupby(\"location_csv\")[\"begin_date\"].diff().shift(-1)\n",
    "  missing_time = missing_time.dropna()\n",
    "  missing_time = missing_time[missing_time['timedelta'] > freq]\n",
    "  missing_time['timedelta'] = missing_time['timedelta'] - freq\n",
    "\n",
    "  # Filter by cutoff values\n",
    "  true_na_vh = missing_time.loc[(missing_time['timedelta'] > timedelta(days = cutoff_Vrijthof)) & (missing_time['location_csv'] == '280324_mp08bis---vrijthof.csv')]\n",
    "  true_na_other = missing_time.loc[(missing_time['timedelta'] > timedelta(days = cutoff)) & (missing_time['location_csv'] != '280324_mp08bis---vrijthof.csv')]\n",
    "\n",
    "\n",
    "  col_to_fill = ts.columns[ts.columns.str.contains('noise')].values.tolist()\n",
    "\n",
    "  ts_vh = ts.loc[ts['location_csv'] == '280324_mp08bis---vrijthof.csv' ].copy()\n",
    "  ts_other = ts.loc[ts['location_csv'] != '280324_mp08bis---vrijthof.csv'].copy()\n",
    "\n",
    "  \n",
    "  # Add column true_na yes/no (less intervals to check for true nans than false nans)\n",
    "  # If timestamp not in true_na, replace any nans with 0s\n",
    "\n",
    "    #Vrijthof\n",
    "  ts_vh['true_na'] = ts_vh['timestamp'].apply(lambda t: any((true_na_vh[\"begin_date\"] <= t) & (true_na_vh[\"end_date\"] > t)))\n",
    "  ts_vh.loc[ts_vh['true_na'] == 0, col_to_fill] = ts_vh.loc[ts_vh['true_na'] == 0, col_to_fill].fillna(0)\n",
    "\n",
    "    #other MPs\n",
    "  other = ts_other['location_csv'].drop_duplicates().tolist()\n",
    "  for MP in other:\n",
    "    ts_other.loc[ts_other['location_csv'] == MP,'true_na'] = ts_other.loc[ts_other['location_csv'] == MP, 'timestamp'] \\\n",
    "                          .apply(lambda t: any((true_na_other['location_csv'] == MP) &(true_na_other[\"begin_date\"] <= t) & (true_na_other[\"end_date\"] > t)))\n",
    "  ts_other.loc[ts_other['true_na'] == 0, col_to_fill] = ts_other.loc[ts_other['true_na'] == 0, col_to_fill].fillna(0)\n",
    "\n",
    "  df = pd.concat([ts_vh, ts_other]).drop('true_na', axis = 1)  \n",
    "\n",
    "  return df, missing_time\n",
    "\n",
    "df, missing = missing_or_noevent(df_hourly)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature building\n",
    "Could still be added: window features, such as 'number of time periods with noise event, out of the last 6 time periods' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "from datetime import timedelta\n",
    "\n",
    "# DEV: \n",
    "## GPT prompt:\n",
    "## if I have a pandas dataframe with timestamps (UTC), can you suggest some additional features to engineer? (for example: weekend, weekday, Belgian holiday, season, ...)\n",
    "## Can you provide python3 code on an imaginary dataframe?\n",
    "\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "# Add weekday/weekend feature\n",
    "df[\"is_weekend\"] = df[\"timestamp\"].dt.weekday.isin([5, 6]).astype(int)\n",
    "\n",
    "# Add day of the week feature\n",
    "df[\"day_of_week\"] = df[\"timestamp\"].dt.day_name()\n",
    "\n",
    "# Add hour of the day feature\n",
    "df[\"hour_of_day\"] = df[\"timestamp\"].dt.hour\n",
    "\n",
    "# Add time of day feature\n",
    "df[\"time_of_day\"] = pd.cut(\n",
    "    df[\"timestamp\"].dt.hour,\n",
    "    bins=[-1, 6, 12, 18, 24],\n",
    "    labels=[\"Night\", \"Morning\", \"Afternoon\", \"Evening\"],\n",
    ")  # equal bins\n",
    "\n",
    "# Add season feature\n",
    "df[\"season\"] = pd.cut(\n",
    "    df[\"timestamp\"].dt.month,\n",
    "    bins=[0, 3, 6, 9, 12],\n",
    "    labels=[\"Winter\", \"Spring\", \"Summer\", \"Fall\"],\n",
    ")\n",
    "\n",
    "# Add month feature\n",
    "df[\"month\"] = df[\"timestamp\"].dt.month_name()\n",
    "\n",
    "# Add day of the month feature\n",
    "df[\"day_of_month\"] = df[\"timestamp\"].dt.day\n",
    "\n",
    "# Add quarter feature\n",
    "df[\"quarter\"] = \"Q\" + df[\"timestamp\"].dt.quarter.astype(str)\n",
    "\n",
    "# Add Belgian holidays feature\n",
    "be_holidays = holidays.BE()\n",
    "df[\"is_be_holiday\"] = (\n",
    "    df[\"timestamp\"].dt.date.astype(\"datetime64[ns]\").isin(be_holidays).astype(int)\n",
    ")\n",
    "\n",
    "# Add business day feature\n",
    "df[\"is_business_day\"] = ~df[\"timestamp\"].dt.weekday.isin([5, 6]) & ~df[\"is_be_holiday\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_csv</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>human_noise</th>\n",
       "      <th>noise_event_human_voice_-_shouting</th>\n",
       "      <th>noise_event_human_voice_-_singing</th>\n",
       "      <th>noise_event_music_non-amplified</th>\n",
       "      <th>noise_event_nature_elements_-_wind</th>\n",
       "      <th>noise_event_transport_road_-_passenger_car</th>\n",
       "      <th>noise_event_transport_road_-_siren</th>\n",
       "      <th>noise_event_unsupported</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_be_holiday</th>\n",
       "      <th>is_business_day</th>\n",
       "      <th>missing</th>\n",
       "      <th>exams</th>\n",
       "      <th>first_exam_weeks</th>\n",
       "      <th>final_exam_week</th>\n",
       "      <th>student_vacation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45765</th>\n",
       "      <td>280324_mp08bis---vrijthof.csv</td>\n",
       "      <td>2022-04-20 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>April</td>\n",
       "      <td>20</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45766</th>\n",
       "      <td>280324_mp08bis---vrijthof.csv</td>\n",
       "      <td>2022-04-20 13:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>April</td>\n",
       "      <td>20</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45767</th>\n",
       "      <td>280324_mp08bis---vrijthof.csv</td>\n",
       "      <td>2022-04-20 14:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>April</td>\n",
       "      <td>20</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45768</th>\n",
       "      <td>280324_mp08bis---vrijthof.csv</td>\n",
       "      <td>2022-04-20 15:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>April</td>\n",
       "      <td>20</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45769</th>\n",
       "      <td>280324_mp08bis---vrijthof.csv</td>\n",
       "      <td>2022-04-20 16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>April</td>\n",
       "      <td>20</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        location_csv           timestamp  human_noise  \\\n",
       "45765  280324_mp08bis---vrijthof.csv 2022-04-20 12:00:00          0.0   \n",
       "45766  280324_mp08bis---vrijthof.csv 2022-04-20 13:00:00          0.0   \n",
       "45767  280324_mp08bis---vrijthof.csv 2022-04-20 14:00:00          0.0   \n",
       "45768  280324_mp08bis---vrijthof.csv 2022-04-20 15:00:00          0.0   \n",
       "45769  280324_mp08bis---vrijthof.csv 2022-04-20 16:00:00          0.0   \n",
       "\n",
       "       noise_event_human_voice_-_shouting  noise_event_human_voice_-_singing  \\\n",
       "45765                                 0.0                                0.0   \n",
       "45766                                 0.0                                0.0   \n",
       "45767                                 0.0                                0.0   \n",
       "45768                                 0.0                                0.0   \n",
       "45769                                 0.0                                0.0   \n",
       "\n",
       "       noise_event_music_non-amplified  noise_event_nature_elements_-_wind  \\\n",
       "45765                              0.0                                 0.0   \n",
       "45766                              0.0                                 0.0   \n",
       "45767                              0.0                                 0.0   \n",
       "45768                              0.0                                 0.0   \n",
       "45769                              0.0                                 0.0   \n",
       "\n",
       "       noise_event_transport_road_-_passenger_car  \\\n",
       "45765                                         1.0   \n",
       "45766                                         0.0   \n",
       "45767                                         0.0   \n",
       "45768                                         0.0   \n",
       "45769                                         0.0   \n",
       "\n",
       "       noise_event_transport_road_-_siren  noise_event_unsupported  ...  \\\n",
       "45765                                 0.0                      0.0  ...   \n",
       "45766                                 0.0                      0.0  ...   \n",
       "45767                                 0.0                      0.0  ...   \n",
       "45768                                 0.0                      0.0  ...   \n",
       "45769                                 0.0                      0.0  ...   \n",
       "\n",
       "       month day_of_month  quarter  is_be_holiday  is_business_day  missing  \\\n",
       "45765  April           20       Q2              0             True    False   \n",
       "45766  April           20       Q2              0             True    False   \n",
       "45767  April           20       Q2              0             True    False   \n",
       "45768  April           20       Q2              0             True    False   \n",
       "45769  April           20       Q2              0             True    False   \n",
       "\n",
       "       exams  first_exam_weeks  final_exam_week  student_vacation  \n",
       "45765  False             False            False             False  \n",
       "45766  False             False            False             False  \n",
       "45767  False             False            False             False  \n",
       "45768  False             False            False             False  \n",
       "45769  False             False            False             False  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add feature indicating whether the response variable is missing\n",
    "df['missing'] = df['human_noise'].isna()\n",
    "\n",
    "# Create dataframe with exam & vacation dates based on the academic calendars 2021-2022 & 2022-2023 of the KU Leuven & KU Leuven Group T \n",
    "# https://www.kuleuven.be/over-kuleuven/kalenders/kalenders-21-22 & https://www.kuleuven.be/over-kuleuven/kalenders \n",
    "# vacation = periods with no lessons or exams lasting at least 1 week\n",
    "kul_ac_year = pd.DataFrame({\"begin_date\": [\"2022-01-10\", \"2022-05-30\", \"2022-01-10\", \"2022-05-30\",\n",
    "                                           \"2022-01-31\", \"2022-06-27\", \"2022-01-01\", \"2022-02-05\",\n",
    "                                           \"2022-04-02\", \"2022-07-02\", \"2022-12-24\"],\n",
    "                    \"end_date\": [\"2022-02-04\", \"2022-07-01\", \"2022-01-30\", \"2022-06-26\", \n",
    "                                 \"2022-02-04\", \"2022-07-01\", \"2022-01-13\", \"2022-02-13\", \n",
    "                                 \"2022-04-18\", \"2022-09-25\", \"2022-12-31\"],\n",
    "                    \"type\": [\"exams\", \"exams\", \"first_exam_weeks\", \"first_exam_weeks\", \n",
    "                             \"final_exam_week\", \"final_exam_week\", \"vacation\", \"vacation\", \n",
    "                             \"vacation\", \"vacation\", \"vacation\"]})\n",
    "\n",
    "kul_ac_year[\"begin_date\"] = pd.to_datetime(kul_ac_year[\"begin_date\"])\n",
    "kul_ac_year[\"end_date\"] = pd.to_datetime(kul_ac_year[\"end_date\"])\n",
    "kul_ac_year[\"end_date\"] = kul_ac_year[\"end_date\"] + pd.Timedelta('23:59:59')\n",
    "\n",
    "kul_ac_year\n",
    "\n",
    "# Add (university) exams feature (only first & second exam period)\n",
    "df[\"exams\"] = df[\"timestamp\"].apply(lambda t: any((kul_ac_year[\"type\"] == \"exams\") & (kul_ac_year[\"begin_date\"] <= t) & (kul_ac_year[\"end_date\"] >= t)))\n",
    "\n",
    "  # Alternatively add 2 features, one for first, 'normal', exam weeks, one for the last week\n",
    "df[\"first_exam_weeks\"] = df[\"timestamp\"].apply(lambda t: any((kul_ac_year[\"type\"] == \"first_exam_weeks\") & (kul_ac_year[\"begin_date\"] <= t) & (kul_ac_year[\"end_date\"] >= t)))\n",
    "df[\"final_exam_week\"] = df[\"timestamp\"].apply(lambda t: any((kul_ac_year[\"type\"] == \"final_exam_week\") & (kul_ac_year[\"begin_date\"] <= t) & (kul_ac_year[\"end_date\"] >= t)))\n",
    "\n",
    "# Add student vacation periods feature\n",
    "df[\"student_vacation\"] = df[\"timestamp\"].apply(lambda t: any((kul_ac_year[\"type\"] == \"vacation\") & (kul_ac_year[\"begin_date\"] <= t) & (kul_ac_year[\"end_date\"] >= t)))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with skforecast and LightGBM\n",
    "Code used as blueprint:\n",
    "Forecasting time series with gradient boosting: Skforecast, XGBoost, LightGBM y CatBoost by Joaquín Amat Rodrigo and Javier Escobar Ortiz, available under a Attribution 4.0 International (CC BY 4.0) at https://www.cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, cohen_kappa_score\n",
    "\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.utils import save_forecaster, load_forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create input dfs\n",
    "# Drop location 08bis due to no human noise events occuring during validation month (November)\n",
    "df = df[df['location_csv'] != '280324_mp08bis---vrijthof.csv']\n",
    "\n",
    "# Create separate df with target time series \n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "ts_data = pd.pivot_table(data = df, values = 'human_noise', index = 'timestamp', columns = 'location_csv')\n",
    "\n",
    "# Additional category for missing response -> multiclass for some locations\n",
    "ts_data = ts_data.fillna(2)\n",
    "ts_data = ts_data.astype('category')\n",
    "\n",
    "# Drop last row (not real data) \n",
    "ts_data.drop(index=ts_data.index[-1],axis=0,inplace=True)\n",
    "\n",
    "# Explicitly set hourly frequency of datetime index\n",
    "ts_data.index.freq = 'H'\n",
    "\n",
    "# Create dictionary with exogenous data for every location \n",
    "# necessary because missing values are location-specific\n",
    "locations = df['location_csv'].drop_duplicates().tolist()\n",
    "exog_datasets = {}\n",
    "\n",
    "for location in locations:\n",
    "  # Subset by location\n",
    "  somename = df.loc[df['location_csv'] == location,:]\n",
    "\n",
    "  # Create df with exogenous vars\n",
    "  cat_exogs = ['missing',\n",
    "              'is_weekend',\n",
    "              'day_of_week',\n",
    "              'time_of_day',\n",
    "              'is_be_holiday',\n",
    "              'is_business_day',\n",
    "              'season',\n",
    "              'month',\n",
    "              'first_exam_weeks', \n",
    "              'final_exam_week',\n",
    "              'student_vacation']\n",
    "  num_exogs = ['hour_of_day',\n",
    "              'LC_TEMP_QCL3', \n",
    "              'LC_WINDSPEED', \n",
    "              'LC_RAININ']\n",
    "\n",
    "  exog_data  = somename[cat_exogs + num_exogs + ['timestamp']].set_index('timestamp').sort_index()\n",
    "  exog_data[cat_exogs] = exog_data[cat_exogs].astype('category')\n",
    "\n",
    "  # Drop last row (not real data) \n",
    "  exog_data.drop(index=exog_data.index[-1],axis=0,inplace=True)\n",
    "\n",
    "  # Explicitly set hourly frequency of datetime index\n",
    "  exog_data.index.freq = 'H'\n",
    "\n",
    "  # Add to dictionary\n",
    "  exog_datasets[location] = exog_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependent multivariate time series analysis with direct multi-step forecasting\n",
    "\n",
    "# Defining train-val-test-split dates,\n",
    "# starting from the time the last sensor began registering events of any type\n",
    "# to minimize missing values in response var and lag predictors\n",
    "start_train = '2022-03-07 22:00:00' \n",
    "end_train = '2022-10-31 23:59:00'\n",
    "end_val = '2022-11-30 23:59:00'\n",
    "\n",
    "# Define metrics to calculate f1-score, recall, and precision for positive label regardless of whether there's an additional 'missing' class\n",
    "def f1score_pos(y_true, y_pred):\n",
    "  scores = f1_score(y_true, y_pred, average = None)\n",
    "  return scores[1]\n",
    "def recall_pos(y_true, y_pred):\n",
    "  scores = recall_score(y_true, y_pred, average = None)\n",
    "  return scores[1]\n",
    "def precision_pos(y_true, y_pred):\n",
    "  scores = precision_score(y_true, y_pred, average = None)\n",
    "  return scores[1]\n",
    "\n",
    "# Transform categorical features using ordinal encoding. \n",
    "# Numeric features are left untouched. \n",
    "# if a new category is found in the test set, it is encoded as -1.\n",
    "\n",
    "pipeline_cat = make_pipeline(OrdinalEncoder(dtype=int, #int dtype required by skforecast \n",
    "                                            handle_unknown=\"use_encoded_value\",\n",
    "                                            unknown_value=-1,),\n",
    "                             FunctionTransformer(func=lambda x: x.astype('category'), \n",
    "                                                 feature_names_out = 'one-to-one'))\n",
    "transformer_exog = make_column_transformer((pipeline_cat, cat_exogs),\n",
    "                                           remainder=\"passthrough\").set_output(transform=\"pandas\")\n",
    "\n",
    "# Define max lags\n",
    "lags = 48\n",
    "\n",
    "# Define forecast horizon\n",
    "h = 12\n",
    "\n",
    "# Define grids\n",
    "lags_grid = {12, 24, 36, 48}\n",
    "param_grid = {'min_child_samples': [10, 20, 30],\n",
    "              'num_leaves': [5, 10, 15, 20, 25]}\n",
    "\n",
    "# Gridsearch for all locations\n",
    "LGBM_gs = {}\n",
    "for level in locations:\n",
    "  \n",
    "  # Different class imbalance per location -> different weights\n",
    "  # -> create custom weights function for every location \n",
    "  # (skforecast only allows a function based on datetime index, not simply a column)\n",
    "  def get_custom_weights(index):\n",
    "    ts_train = ts_data.loc[start_train:end_val, level]\n",
    "    ts = ts_data.loc[start_train:, level]\n",
    "    minority_weight = ts_train.value_counts()[0] / ts_train.value_counts()[1]\n",
    "    weights = np.where(ts == 1, minority_weight, 1)\n",
    "    w = weights[:len(index)]\n",
    "    return w\n",
    "\n",
    "  # Define main performance measure cohen's kappa\n",
    "  def kappa(y_true, y_pred):\n",
    "    score = cohen_kappa_score(y_true, y_pred, labels = [0,1], sample_weight = get_custom_weights(ts_data.loc[end_train:end_val].index))\n",
    "    return score\n",
    "  \n",
    "  # Initializing the forecaster\n",
    "  forecaster = ForecasterAutoregMultiVariate(regressor = LGBMClassifier(categorical_features='auto', random_state=123, max_depth = 6),\n",
    "                                            lags = lags,\n",
    "                                            level = level,\n",
    "                                            steps = h, \n",
    "                                            transformer_exog = transformer_exog,\n",
    "                                            weight_func = get_custom_weights\n",
    "  )\n",
    "\n",
    "  # Grid search\n",
    "  result = grid_search_forecaster_multiseries(forecaster = forecaster,\n",
    "                                                series = ts_data.loc[start_train:end_val, :],\n",
    "                                                exog = exog_datasets[level].loc[start_train:end_val],\n",
    "                                                lags_grid = lags_grid,\n",
    "                                                param_grid = param_grid,\n",
    "                                                steps = h,\n",
    "                                                metric = [kappa, f1score_pos, recall_pos, precision_pos],\n",
    "                                                initial_train_size = len(ts_data.loc[start_train:end_train]),\n",
    "                                                refit = False, #if true, we'd assume we'd retrain model every 12 hours in production\n",
    "                                                fixed_train_size = False, #assumes influx of new response values every 12 hours\n",
    "                                                return_best = False,\n",
    "                                                verbose = False\n",
    "  )      \n",
    "  #print(result.to_string())\n",
    "  LGBM_gs[level] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255439_mp-01-naamsestraat-35-maxim.csv\n",
      "kappa            0.567213\n",
      "f1score_pos      0.566667\n",
      "recall_pos       0.441558\n",
      "precision_pos    0.790698\n",
      "Name: 0, dtype: object\n",
      "255440_mp-02-naamsestraat-57-xior.csv\n",
      "kappa            0.193189\n",
      "f1score_pos      0.057143\n",
      "recall_pos       0.033333\n",
      "precision_pos         0.2\n",
      "Name: 0, dtype: object\n",
      "255441_mp-03-naamsestraat-62-taste.csv\n",
      "kappa            0.469517\n",
      "f1score_pos      0.241379\n",
      "recall_pos          0.175\n",
      "precision_pos    0.388889\n",
      "Name: 0, dtype: object\n",
      "255442_mp-05-calvariekapel-ku-leuven.csv\n",
      "kappa            0.149263\n",
      "f1score_pos      0.136364\n",
      "recall_pos           0.08\n",
      "precision_pos    0.461538\n",
      "Name: 0, dtype: object\n",
      "255443_mp-06-parkstraat-2-la-filosovia.csv\n",
      "kappa            0.018144\n",
      "f1score_pos      0.086957\n",
      "recall_pos       0.045455\n",
      "precision_pos         1.0\n",
      "Name: 0, dtype: object\n",
      "255444_mp-07-naamsestraat-81.csv\n",
      "kappa            0.154863\n",
      "f1score_pos      0.111111\n",
      "recall_pos       0.066667\n",
      "precision_pos    0.333333\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for level in locations:\n",
    "  gs = LGBM_gs[level]\n",
    "  best = gs.sort_values('kappa', ascending = False).reset_index().loc[0, ['kappa', 'f1score_pos', 'recall_pos', 'precision_pos']]\n",
    "  print(level)\n",
    "  print(best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model & fitting it on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining train-val-test-split dates,\n",
    "# starting from the time the last sensor began registering events of any type\n",
    "# to minimize missing values in response var and lag predictors\n",
    "start_train = '2022-03-07 22:00:00' \n",
    "end_train = '2022-10-31 23:59:00'\n",
    "end_val = '2022-11-30 23:59:00'\n",
    "\n",
    "# Define metrics to calculate f1-score, recall, and precision for every label separately\n",
    "def f1score(y_true, y_pred):\n",
    "  scores = f1_score(y_true, y_pred, average = None)\n",
    "  return scores  \n",
    "def recall(y_true, y_pred):\n",
    "  scores = recall_score(y_true, y_pred, average = None)\n",
    "  return scores\n",
    "def precision(y_true, y_pred):\n",
    "  scores = precision_score(y_true, y_pred, average = None)\n",
    "  return scores\n",
    "\n",
    "# Define function to change column type to categorical, since lambda function cannot be saved by built-in method\n",
    "def to_cat(x):\n",
    "  x = x.astype('category')\n",
    "  return x\n",
    "\n",
    "# Transform categorical features using ordinal encoding. \n",
    "# Numeric features are left untouched. \n",
    "# if a new category is found in the test set, it is encoded as -1.\n",
    "pipeline_cat = make_pipeline(OrdinalEncoder(dtype=int, # int dtype required by skforecast \n",
    "                                            handle_unknown=\"use_encoded_value\",\n",
    "                                           unknown_value=-1,),\n",
    "                             FunctionTransformer(func = to_cat, \n",
    "                                                 feature_names_out = 'one-to-one'))\n",
    "transformer_exog = make_column_transformer((pipeline_cat, cat_exogs),\n",
    "                                           remainder=\"passthrough\").set_output(transform=\"pandas\")\n",
    "\n",
    "# Define forecast horizon\n",
    "h = 12 \n",
    "\n",
    "# Testing best model for each location \n",
    "# And fitting each of those on all data\n",
    "metrics_best = pd.DataFrame()\n",
    "predictions_best = {}\n",
    "forecasters = {}\n",
    "\n",
    "for level in locations:\n",
    "  gs = LGBM_gs[level]\n",
    "  min_child_samples = gs.sort_values('kappa', ascending = False).reset_index().loc[0, 'min_child_samples']\n",
    "  num_leaves = gs.sort_values('kappa', ascending = False).reset_index().loc[0, 'num_leaves']\n",
    "  lags = gs.sort_values('kappa', ascending = False).reset_index().loc[0, 'lags']\n",
    "\n",
    "  # Different class imbalance per location -> different weights\n",
    "  # -> create custom weights function for every location \n",
    "  # (skforecast only allows a function based on datetime index, not simply a column)\n",
    "  def get_custom_weights(index):\n",
    "    ts_train = ts_data.loc[start_train:end_val, level]\n",
    "    ts = ts_data.loc[start_train:, level]\n",
    "    minority_weight = ts_train.value_counts()[0] / ts_train.value_counts()[1]\n",
    "    weights = np.where(ts == 1, minority_weight, 1)\n",
    "    w = weights[:len(index)]\n",
    "    return w\n",
    "\n",
    "  # Define main performance measure cohen's kappa\n",
    "  def kappa(y_true, y_pred):\n",
    "    score = cohen_kappa_score(y_true, y_pred, labels = [0,1], sample_weight = get_custom_weights(ts_data.loc[end_val:].index))\n",
    "    return score\n",
    "  \n",
    "  # Initializing the forecaster\n",
    "  forecaster = ForecasterAutoregMultiVariate(regressor = LGBMClassifier(categorical_features='auto', \n",
    "                                                                        random_state=123,\n",
    "                                                                        min_child_samples = min_child_samples,\n",
    "                                                                        num_leaves = num_leaves,\n",
    "                                                                        max_depth = 6\n",
    "                                                                        ),\n",
    "                                            lags = lags,\n",
    "                                            level = level,\n",
    "                                            steps = h, \n",
    "                                            transformer_exog = transformer_exog,\n",
    "                                            weight_func = get_custom_weights\n",
    "  )\n",
    "  \n",
    "  # Testing best model for each location \n",
    "  metric_best, preds_best = backtesting_forecaster_multiseries(forecaster = forecaster,\n",
    "                                                series = ts_data.loc[start_train:],\n",
    "                                                exog = exog_datasets[level].loc[start_train:],\n",
    "                                                steps = h,\n",
    "                                                metric = [kappa, f1score, recall, precision],\n",
    "                                                initial_train_size = len(ts_data.loc[start_train:end_val]),\n",
    "                                                refit = False,\n",
    "                                                fixed_train_size = False,\n",
    "                                                verbose = False\n",
    "  )\n",
    "  metrics_best = pd.concat([metrics_best, metric_best])\n",
    "  predictions_best[level] = preds_best \n",
    "\n",
    "  # Training best model for each location on all data\n",
    "  forecaster.fit(series = ts_data.loc[start_train:],\n",
    "                 exog = exog_datasets[level].loc[start_train:])    \n",
    "\n",
    "  forecasters[level] = forecaster \n",
    "  name = level[:-4]\n",
    "  save_forecaster(forecaster, file_name = f\"../models/forecasters/forecaster_h12_{name}.pkl\", verbose = False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255439_mp-01-naamsestraat-35-maxim.csv</td>\n",
       "      <td>0.449345</td>\n",
       "      <td>[0.9060402684563759, 0.4246575342465753, 1.0]</td>\n",
       "      <td>[0.9759036144578314, 0.29523809523809524, 1.0]</td>\n",
       "      <td>[0.8455114822546973, 0.7560975609756098, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255440_mp-02-naamsestraat-57-xior.csv</td>\n",
       "      <td>-0.001180</td>\n",
       "      <td>[0.9754178957718781, 0.0, 1.0]</td>\n",
       "      <td>[0.9979879275653923, 0.0, 1.0]</td>\n",
       "      <td>[0.9538461538461539, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255441_mp-03-naamsestraat-62-taste.csv</td>\n",
       "      <td>-0.013441</td>\n",
       "      <td>[0.9794238683127572, 0.0]</td>\n",
       "      <td>[0.9986013986013986, 0.0]</td>\n",
       "      <td>[0.9609690444145357, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255442_mp-05-calvariekapel-ku-leuven.csv</td>\n",
       "      <td>0.187268</td>\n",
       "      <td>[0.9592696629213483, 0.09375]</td>\n",
       "      <td>[0.9927325581395349, 0.05357142857142857]</td>\n",
       "      <td>[0.9279891304347826, 0.375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255443_mp-06-parkstraat-2-la-filosovia.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.9829118250170883, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.9663978494623656, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255444_mp-07-naamsestraat-81.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.9863760217983651, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.9731182795698925, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       levels     kappa  \\\n",
       "0      255439_mp-01-naamsestraat-35-maxim.csv  0.449345   \n",
       "0       255440_mp-02-naamsestraat-57-xior.csv -0.001180   \n",
       "0      255441_mp-03-naamsestraat-62-taste.csv -0.013441   \n",
       "0    255442_mp-05-calvariekapel-ku-leuven.csv  0.187268   \n",
       "0  255443_mp-06-parkstraat-2-la-filosovia.csv  0.000000   \n",
       "0            255444_mp-07-naamsestraat-81.csv  0.000000   \n",
       "\n",
       "                                         f1score  \\\n",
       "0  [0.9060402684563759, 0.4246575342465753, 1.0]   \n",
       "0                 [0.9754178957718781, 0.0, 1.0]   \n",
       "0                      [0.9794238683127572, 0.0]   \n",
       "0                  [0.9592696629213483, 0.09375]   \n",
       "0                      [0.9829118250170883, 0.0]   \n",
       "0                      [0.9863760217983651, 0.0]   \n",
       "\n",
       "                                           recall  \\\n",
       "0  [0.9759036144578314, 0.29523809523809524, 1.0]   \n",
       "0                  [0.9979879275653923, 0.0, 1.0]   \n",
       "0                       [0.9986013986013986, 0.0]   \n",
       "0       [0.9927325581395349, 0.05357142857142857]   \n",
       "0                                      [1.0, 0.0]   \n",
       "0                                      [1.0, 0.0]   \n",
       "\n",
       "                                       precision  \n",
       "0  [0.8455114822546973, 0.7560975609756098, 1.0]  \n",
       "0                 [0.9538461538461539, 0.0, 1.0]  \n",
       "0                      [0.9609690444145357, 0.0]  \n",
       "0                    [0.9279891304347826, 0.375]  \n",
       "0                      [0.9663978494623656, 0.0]  \n",
       "0                      [0.9731182795698925, 0.0]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_best\n",
    "# many f1-scores for positive label are 0 due to either no true postives, \n",
    "# or no predicted positives (undefined f1-score/recall/precision defaults to 0)\n",
    "# If missing values are a label, its f1-score = 1, \n",
    "# indicating that adding the missing-value variable worked as intended"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible reasons for bad performance:\n",
    "   1. The event data may be of questionable quality due to event sensors not registering events properly or at all, and/or errors by model that was used to classify events as human noise, car, etc.\n",
    "   2. Predictors may not be powerful enough.\n",
    "   3. Way of measuring performance is all or nothing, no way to measure closeness (in time) of predictions. Example: true values(hour 4 = 0, hour 5 = 1) vs predicted values(hour 4 = 1, hour 5 = 0) counts as 2 wrong predictions, even though they are not far off in time. \n",
    "   4. Limited time coverage of the training data. Model training period encompasses spring, summer, and half of fall. Validation and test encompasses second half of fall and beginning of winter. This results in many unseen values and unseen combinations of values (e.g. month, temperature (unseen minima))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load forecasters & use them to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>255439_mp-01-naamsestraat-35-maxim.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 06:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     255439_mp-01-naamsestraat-35-maxim.csv\n",
       "2023-01-01 06:00:00                                     0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all forecasters\n",
    "loaded_forecasters = {}\n",
    "for level in locations:\n",
    "  name = level[:-4]\n",
    "  loaded_forecaster = load_forecaster(file_name = f\"../models/forecasters/forecaster_h12_{name}.pkl\", verbose = False)\n",
    "  loaded_forecasters[level] = loaded_forecaster\n",
    "\n",
    "# Create dataframe with all of the exogeneous variables that were used to train model\n",
    "# values for weather can/should be made adaptable through sliders \n",
    "# You can use the same exog dataframe for all locations\n",
    "# here I just take a part of a training exog_data and overwrite its timestamps, obviously don't do that in the app implementation\n",
    "exog = exog_datasets['255443_mp-06-parkstraat-2-la-filosovia.csv'][500:512].reset_index().set_index(pd.date_range(start = '2023.01.01 00:00:00', periods = 12, freq = 'H'))\n",
    "\n",
    "# Generate predictions for the next 12 hours for one location\n",
    "loaded_forecasters['255439_mp-01-naamsestraat-35-maxim.csv'].predict(steps = 12, exog = exog)\n",
    "\n",
    "# Generate prediction for the 7th hour\n",
    "loaded_forecasters['255439_mp-01-naamsestraat-35-maxim.csv'].predict(steps = [7], exog = exog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDA_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
